{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2020 Course Projects\n",
    "\n",
    "## Project Schedule\n",
    "\n",
    "In this project, you will solve a real-life problem with a dataset. The project will be separated into two phases:\n",
    "\n",
    "27th May - 10th June: We will give you a training set with target values and a testing set without target. You predict the target of the testing set by trying different machine learning models and submit your best result to us and we will evaluate your results first time at the end of phase 1.\n",
    "\n",
    "9th June - 24th June: Students stand high in the leader board will briefly explain  their submission in a proseminar. We will also release some general advice to improve the result. You try to improve your prediction and submit final results in the end. We will again ask random group to present and show their implementation.\n",
    "The project shall be finished by a team of two people. Please find your teammate and REGISTER via [here](https://docs.google.com/forms/d/e/1FAIpQLSf4uAQwBkTbN12E0akQdxfXLgUQLObAVDRjqJHcNAUFwvRTsg/alreadyresponded).\n",
    "\n",
    "The submission and evaluation is processed by [Kaggle](https://www.kaggle.com/t/b3dc81e90d32436d93d2b509c98d0d71).  In order to submit, you need to create an account, please use your team name in the `team tag` on the [kaggle page](https://www.kaggle.com/t/b3dc81e90d32436d93d2b509c98d0d71). Two people can submit as a team in Kaggle.\n",
    "\n",
    "You can submit and test your result on the test set 2 times a day, you will be able to upload your predicted value in a CSV file and your result will be shown on a leaderboard. We collect data for grading at 22:00 on the **last day of each phase**. Please secure your best results before this time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Car insurance companies are always trying to come up with a fair insurance plan for customers. They would like to offer a lower price to the careful and safe driver while the careless drivers who file claims in the past will pay more. In addition, more safe drivers mean that the company will spend less in operation. However, for new customers, it is difficult for the company to know who the safe driver is. As a result, if a company offers a low price, it bears a high risk of cost. If not, the company loses competitiveness and encourage new customers to choose its competitors.\n",
    "\n",
    "\n",
    "Your task is to create a machine learning model to mitigate this problem by identifying the safe drivers in new customers based on their profiles. The company then offers them a low price to boost safe customer acquirement and reduce risks of costs. We provide you with a dataset (train_set.csv) regarding the profile (columns starting with ps_*) of customers. You will be asked to predict whether a customer will file a claim (`target`) in the next year with the test_set.csv \n",
    "\n",
    "~~You can find the dataset in the `project` folders in the jupyter hub.~~ We also upload dataset to Kaggle and will test your result and offer you a leaderboard in Kaggle. Please find them under the Data tag on the following page:\n",
    "https://www.kaggle.com/t/b3dc81e90d32436d93d2b509c98d0d71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: 26th May - 9th June\n",
    "\n",
    "### Data Description\n",
    "\n",
    "In order to take a look at the data, you can use the `describe()` method. As you can see in the result, each row has a unique `id`. `Target` $\\in \\{0, 1\\}$ is whether a user will file a claim in his insurance period. The rest of the 57 columns are features regarding customers' profiles. You might also notice that some of the features have minimum values of `-1`. This indicates that the actual value is missing or inaccessible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick load dataset and check\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\train_set.csv\"\n",
    "data_train = pd.read_csv(filename)\n",
    "filename = r\"C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\test_set.csv\"\n",
    "data_test = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.464100e+05</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "      <td>446410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.578496e+05</td>\n",
       "      <td>0.036449</td>\n",
       "      <td>1.898952</td>\n",
       "      <td>1.359105</td>\n",
       "      <td>4.424744</td>\n",
       "      <td>0.417054</td>\n",
       "      <td>0.405022</td>\n",
       "      <td>0.393829</td>\n",
       "      <td>0.256701</td>\n",
       "      <td>0.164047</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441536</td>\n",
       "      <td>1.442483</td>\n",
       "      <td>2.872330</td>\n",
       "      <td>7.538823</td>\n",
       "      <td>0.122685</td>\n",
       "      <td>0.627835</td>\n",
       "      <td>0.554569</td>\n",
       "      <td>0.287762</td>\n",
       "      <td>0.348948</td>\n",
       "      <td>0.153668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.219297e+05</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>1.984344</td>\n",
       "      <td>0.665016</td>\n",
       "      <td>2.702142</td>\n",
       "      <td>0.493345</td>\n",
       "      <td>1.349971</td>\n",
       "      <td>0.488598</td>\n",
       "      <td>0.436814</td>\n",
       "      <td>0.370318</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332302</td>\n",
       "      <td>1.203418</td>\n",
       "      <td>1.693303</td>\n",
       "      <td>2.746262</td>\n",
       "      <td>0.328076</td>\n",
       "      <td>0.483382</td>\n",
       "      <td>0.497014</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.476638</td>\n",
       "      <td>0.360631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.793988e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.576260e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.364448e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.115554e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
       "count  4.464100e+05  446410.000000  446410.000000  446410.000000   \n",
       "mean   5.578496e+05       0.036449       1.898952       1.359105   \n",
       "std    3.219297e+05       0.187404       1.984344       0.665016   \n",
       "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
       "25%    2.793988e+05       0.000000       0.000000       1.000000   \n",
       "50%    5.576260e+05       0.000000       1.000000       1.000000   \n",
       "75%    8.364448e+05       0.000000       3.000000       2.000000   \n",
       "max    1.115554e+06       1.000000       7.000000       4.000000   \n",
       "\n",
       "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
       "count  446410.000000  446410.000000  446410.000000  446410.000000   \n",
       "mean        4.424744       0.417054       0.405022       0.393829   \n",
       "std         2.702142       0.493345       1.349971       0.488598   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       0.000000       0.000000       0.000000   \n",
       "75%         6.000000       1.000000       0.000000       1.000000   \n",
       "max        11.000000       1.000000       6.000000       1.000000   \n",
       "\n",
       "       ps_ind_07_bin  ps_ind_08_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  446410.000000  446410.000000  ...  446410.000000  446410.000000   \n",
       "mean        0.256701       0.164047  ...       5.441536       1.442483   \n",
       "std         0.436814       0.370318  ...       2.332302       1.203418   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         1.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  446410.000000  446410.000000   446410.000000   446410.000000   \n",
       "mean        2.872330       7.538823        0.122685        0.627835   \n",
       "std         1.693303       2.746262        0.328076        0.483382   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      23.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   446410.000000   446410.000000   446410.000000   446410.000000  \n",
       "mean         0.554569        0.287762        0.348948        0.153668  \n",
       "std          0.497014        0.452720        0.476638        0.360631  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefix, e.g. `ind` and `calc`, indicate the feature belongs to similiar groupings. The postfix `bin` indicates binary features and `cat` indicates categorical features. The features without postfix are ordinal or continuous. Similarly, you can check the statistics for testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>148800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>174399.500000</td>\n",
       "      <td>1.904651</td>\n",
       "      <td>1.358461</td>\n",
       "      <td>4.419032</td>\n",
       "      <td>0.416022</td>\n",
       "      <td>0.405692</td>\n",
       "      <td>0.393474</td>\n",
       "      <td>0.258031</td>\n",
       "      <td>0.163548</td>\n",
       "      <td>0.184946</td>\n",
       "      <td>...</td>\n",
       "      <td>5.440887</td>\n",
       "      <td>1.440228</td>\n",
       "      <td>2.872157</td>\n",
       "      <td>7.539657</td>\n",
       "      <td>0.121647</td>\n",
       "      <td>0.627863</td>\n",
       "      <td>0.553024</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>0.349254</td>\n",
       "      <td>0.152272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42955.004365</td>\n",
       "      <td>1.982130</td>\n",
       "      <td>0.663332</td>\n",
       "      <td>2.693171</td>\n",
       "      <td>0.493212</td>\n",
       "      <td>1.352667</td>\n",
       "      <td>0.488522</td>\n",
       "      <td>0.437553</td>\n",
       "      <td>0.369867</td>\n",
       "      <td>0.388255</td>\n",
       "      <td>...</td>\n",
       "      <td>2.334537</td>\n",
       "      <td>1.201600</td>\n",
       "      <td>1.699644</td>\n",
       "      <td>2.747838</td>\n",
       "      <td>0.326878</td>\n",
       "      <td>0.483376</td>\n",
       "      <td>0.497182</td>\n",
       "      <td>0.451627</td>\n",
       "      <td>0.476736</td>\n",
       "      <td>0.359285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>137199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>174399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>211599.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>248799.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
       "count  148800.000000  148800.000000  148800.000000  148800.000000   \n",
       "mean   174399.500000       1.904651       1.358461       4.419032   \n",
       "std     42955.004365       1.982130       0.663332       2.693171   \n",
       "min    100000.000000       0.000000      -1.000000       0.000000   \n",
       "25%    137199.750000       0.000000       1.000000       2.000000   \n",
       "50%    174399.500000       1.000000       1.000000       4.000000   \n",
       "75%    211599.250000       3.000000       2.000000       6.000000   \n",
       "max    248799.000000       7.000000       4.000000      11.000000   \n",
       "\n",
       "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  148800.000000  148800.000000  148800.000000  148800.000000   \n",
       "mean        0.416022       0.405692       0.393474       0.258031   \n",
       "std         0.493212       1.352667       0.488522       0.437553   \n",
       "min        -1.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       0.000000       1.000000       1.000000   \n",
       "max         1.000000       6.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
       "count  148800.000000  148800.000000  ...  148800.000000  148800.000000   \n",
       "mean        0.163548       0.184946  ...       5.440887       1.440228   \n",
       "std         0.369867       0.388255  ...       2.334537       1.201600   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
       "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
       "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
       "max         1.000000       1.000000  ...      18.000000       9.000000   \n",
       "\n",
       "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
       "count  148800.000000  148800.000000   148800.000000   148800.000000   \n",
       "mean        2.872157       7.539657        0.121647        0.627863   \n",
       "std         1.699644       2.747838        0.326878        0.483376   \n",
       "min         0.000000       0.000000        0.000000        0.000000   \n",
       "25%         2.000000       6.000000        0.000000        0.000000   \n",
       "50%         3.000000       7.000000        0.000000        1.000000   \n",
       "75%         4.000000       9.000000        0.000000        1.000000   \n",
       "max        13.000000      22.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   148800.000000   148800.000000   148800.000000   148800.000000  \n",
       "mean         0.553024        0.285444        0.349254        0.152272  \n",
       "std          0.497182        0.451627        0.476736        0.359285  \n",
       "min          0.000000        0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000        0.000000  \n",
       "50%          1.000000        0.000000        0.000000        0.000000  \n",
       "75%          1.000000        1.000000        1.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "### Example\n",
    "\n",
    "We will use the decision tree classifier as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Select target and features\n",
    "\n",
    "fea_col = data_train.columns[2:]\n",
    "\n",
    "data_Y = data_train['target']\n",
    "data_X = data_train[fea_col]\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(data_X,data_Y)\n",
    "y_pred = clf.predict(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>818751</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472508</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236368</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34973</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446405</th>\n",
       "      <td>693906</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446406</th>\n",
       "      <td>1066477</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446407</th>\n",
       "      <td>179627</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446408</th>\n",
       "      <td>1026436</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446409</th>\n",
       "      <td>501454</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446410 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0        818751       1          3              1          5              0   \n",
       "1        472508       0          3              3          7              1   \n",
       "2        688265       0          0              2          0              1   \n",
       "3        236368       0          1              1          5              1   \n",
       "4         34973       0          5              3          5              1   \n",
       "...         ...     ...        ...            ...        ...            ...   \n",
       "446405   693906       0          1              4          8              1   \n",
       "446406  1066477       0          3              1          4              0   \n",
       "446407   179627       0          3              1          3              0   \n",
       "446408  1026436       0          5              3          7              1   \n",
       "446409   501454       0          4              1          4              0   \n",
       "\n",
       "        ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0                   0              0              1              0  ...   \n",
       "1                   0              0              1              0  ...   \n",
       "2                   0              0              0              0  ...   \n",
       "3                   2              0              1              0  ...   \n",
       "4                   0              0              0              0  ...   \n",
       "...               ...            ...            ...            ...  ...   \n",
       "446405              0              0              1              0  ...   \n",
       "446406              0              0              0              1  ...   \n",
       "446407              0              1              0              0  ...   \n",
       "446408              0              0              1              0  ...   \n",
       "446409              0              0              0              1  ...   \n",
       "\n",
       "        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0                5           2           2           7               0   \n",
       "1                6           2           1           5               0   \n",
       "2                3           0           1           7               0   \n",
       "3               12           2           1           9               0   \n",
       "4                3           4           1           5               0   \n",
       "...            ...         ...         ...         ...             ...   \n",
       "446405           4           1           4           6               0   \n",
       "446406           3           2           3           5               0   \n",
       "446407           3           0           3           6               0   \n",
       "446408           4           0           0           5               0   \n",
       "446409           6           0           1           7               0   \n",
       "\n",
       "        ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0                    1               0               0               1   \n",
       "1                    1               0               1               0   \n",
       "2                    0               0               0               0   \n",
       "3                    1               0               0               1   \n",
       "4                    1               1               0               1   \n",
       "...                ...             ...             ...             ...   \n",
       "446405               0               1               1               1   \n",
       "446406               1               1               1               0   \n",
       "446407               0               1               0               0   \n",
       "446408               0               1               0               1   \n",
       "446409               1               0               0               1   \n",
       "\n",
       "        ps_calc_20_bin  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "446405               0  \n",
       "446406               0  \n",
       "446407               0  \n",
       "446408               0  \n",
       "446409               0  \n",
       "\n",
       "[446410 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==data_Y)/len(data_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**The decision tree has 100 percent accurate rate!**\n",
    "\n",
    "It is unbelievable! What went wrong?\n",
    "\n",
    "Hint: What is validation?\n",
    "\n",
    "After fixing the problem, you may start here and try to improve the accurate rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_X, data_Y, test_size = 0.3, shuffle = True)\n",
    "clf = DecisionTreeClassifier(min_impurity_decrease = 0.001)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636358205834696"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==y_val)/len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Beyond above Accuracy \n",
    "\n",
    "The result looks promising. **Let us take a look into the results further.**\n",
    "\n",
    "We now make a prediction for the valid set with label-1 data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extrac_one_label(x_val, y_val, label):\n",
    "    X_pos = x_val[y_val == label]\n",
    "    y_pos = y_val[y_val == label]\n",
    "    return X_pos, y_pos\n",
    "\n",
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = clf.predict(X_pos)\n",
    "sum(y_pospred==y_pos)/len(y_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**None of the label is detected!** Now with label-0 data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = clf.predict(X_neg)\n",
    "sum(y_negpred==y_neg)/len(y_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turns:\n",
    "\n",
    "What does it mean? Why does it look like that? How do you overcome it and get the better results? Hint :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635514437400596 16271\n"
     ]
    }
   ],
   "source": [
    "print(sum(data_Y==0)/len(data_Y), sum(data_Y==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9635514437400596 430139\n"
     ]
    }
   ],
   "source": [
    "print(sum(data_Y==0)/len(data_Y), sum(data_Y==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation metric\n",
    "Think about what the proper metric is to train your model and how you should  change your training procedure to aviod this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the number of trees in a random forest\n",
    "def converger(x_train, y_train, x_val, y_val, threshold = 0.0001, steps = 100, stepmax = 25):\n",
    "    crit = 0.45\n",
    "    prev_crit = 0.4\n",
    "    est = 1\n",
    "    params = 0\n",
    "    stepsize = stepmax\n",
    "    down = False\n",
    "    up = False\n",
    "    for i in range(0, steps):\n",
    "        print('loop no: ', i, ' crit is: ', crit, ' est is: ', est)\n",
    "        if crit - prev_crit > threshold:\n",
    "            est += stepsize\n",
    "            prev_crit = crit\n",
    "            crit = trainer(est, x_train, y_train, x_val, y_val)\n",
    "            up = True\n",
    "            if down == True and up == True:\n",
    "                if stepsize == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    stepsize = stepsize //2\n",
    "                    print('Reducing step size to: ', stepsize)\n",
    "                    down = False\n",
    "                    up = False\n",
    "        elif crit - prev_crit < -threshold:\n",
    "            est -= stepsize\n",
    "            prev_crit = crit\n",
    "            crit = trainer(est, x_train, y_train, x_val, y_val)\n",
    "            down = True\n",
    "            if down == True and up == True:\n",
    "                if stepsize == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    stepsize = stepsize //2\n",
    "                    print('Reducing step size to: ', stepsize)\n",
    "                    down = False\n",
    "                    up = False\n",
    "        else:\n",
    "            params = est\n",
    "            break\n",
    "    return params\n",
    "# define the tree and calculate the scores\n",
    "def trainer(est, x_train, y_train, x_val, y_val):\n",
    "    clf = RandomForestClassifier(n_estimators = est,\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 6,\n",
    "                             min_samples_leaf = 29,\n",
    "                             max_features = 16,\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 24.9,0:1.71},\n",
    "                             min_impurity_decrease = 0.00)\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    crit = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "    return crit   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global stats\n",
    "stats = []\n",
    "#optimize tree features\n",
    "def tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   max_depth,min_samples_split,\n",
    "                   min_samples_leaf,max_features,\n",
    "                   min_impurity_decrease, threshold = 0.0001, steps = 100, stepmax = 25,option = 'max_depth'):\n",
    "    crit = 0.4\n",
    "    prev_crit = 0.3\n",
    "    est = 1\n",
    "    params = 0\n",
    "    stepsize = stepmax\n",
    "    down = False\n",
    "    up = False\n",
    "#     max_depth = 12\n",
    "#     min_samples_split = 2\n",
    "#     min_samples_leaf = 2\n",
    "#     max_features = 8\n",
    "    top = [max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease,crit]\n",
    "    for i in range(0, steps):\n",
    "#         print('loop no: ', i, ' crit is: ', crit, ' est is: ', est)\n",
    "        if crit - prev_crit > threshold:\n",
    "            est += stepsize\n",
    "            prev_crit = crit\n",
    "            if est < 1:\n",
    "                est = 1\n",
    "            if option == 'max_depth':\n",
    "                max_depth = est\n",
    "            if option == 'min_samples_split':\n",
    "                min_samples_split = est\n",
    "                if min_samples_split == 1:\n",
    "                    min_samples_split = 2\n",
    "            if option == 'min_samples_leaf':\n",
    "                min_samples_leaf = est\n",
    "            if option == 'max_features':\n",
    "                max_features = est\n",
    "                if max_features > 55:\n",
    "                    max_features = 55\n",
    "            if option == 'min_impurity_decrease':\n",
    "                min_impurity_decrease = est\n",
    "            crit = tree_trainer(x_train, y_train, x_val, y_val,\n",
    "                 max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease)\n",
    "            up = True\n",
    "            if down == True and up == True:\n",
    "                if stepsize == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    stepsize = stepsize //2\n",
    "                    print('Reducing step size to: ', stepsize)\n",
    "                    down = False\n",
    "                    up = False\n",
    "            params = est\n",
    "        elif crit - prev_crit < -threshold:\n",
    "            est -= stepsize\n",
    "            prev_crit = crit\n",
    "            if est < 1:\n",
    "                est = 1\n",
    "            if option == 'max_depth':\n",
    "                max_depth = est\n",
    "            if option == 'min_samples_split':\n",
    "                min_samples_split = est\n",
    "                if min_samples_split == 1:\n",
    "                    min_samples_split = 2\n",
    "            if option == 'min_samples_leaf':\n",
    "                min_samples_leaf = est\n",
    "            if option == 'max_features':\n",
    "                max_features = est\n",
    "            if option == 'min_impurity_decrease':\n",
    "                min_impurity_decrease = est/10000\n",
    "            crit = tree_trainer(x_train, y_train, x_val, y_val,\n",
    "                 max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease)\n",
    "            down = True\n",
    "            if down == True and up == True:\n",
    "                if stepsize == 1:\n",
    "                    break\n",
    "                else:\n",
    "                    stepsize = stepsize //2\n",
    "                    print('Reducing step size to: ', stepsize)\n",
    "                    down = False\n",
    "                    up = False\n",
    "            params = est\n",
    "        elif (crit - prev_crit) < threshold and crit != 0.4:\n",
    "            params = est\n",
    "            break\n",
    "        if crit == prev_crit:\n",
    "            crit = 0.4\n",
    "        if crit > prev_crit:\n",
    "            top = [max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease,crit]\n",
    "#         print(top)\n",
    "#         print(max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease,crit)\n",
    "    return params,crit,top\n",
    "#define tree parameters\n",
    "def tree_trainer(x_train, y_train, x_val, y_val,\n",
    "                 max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease):\n",
    "    clf = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                 splitter = \"best\",\n",
    "                                 max_depth = max_depth,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_features = max_features,\n",
    "                                 class_weight = {1: 11.55,0:0.85752},\n",
    "                                 min_impurity_decrease = min_impurity_decrease)\n",
    "    clf.fit(x_train, y_train)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    crit = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "#     global stats\n",
    "    stats.append([max_depth,min_samples_split,min_samples_leaf,max_features,min_impurity_decrease,crit])\n",
    "    \n",
    "    return crit  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\cerb_\\Anaconda3\\envs\\Machine_learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow.keras.backend as K\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.13.2\n",
      "Eager execution: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "imputer.fit(data_X)\n",
    "X = imputer.transform(data_X)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_fit=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413868 new random picked points\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(X_fit, data_Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_ros, y_ros, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(57,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(32, activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(24, activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "# \tkeras.layers.Dense(32, activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(24, activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(6, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "opter = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=opter,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 = RandomUnderSampler()\n",
    "X_ros2, y_ros2 = ros2.fit_resample(X_fit, data_Y.values)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_ros, y_ros, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6599 - acc: 0.6053\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6598 - acc: 0.6036\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6595 - acc: 0.6045\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6591 - acc: 0.6049\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6588 - acc: 0.6054\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6586 - acc: 0.6058\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6583 - acc: 0.6063\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6580 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6576 - acc: 0.6078\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6574 - acc: 0.6059\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6572 - acc: 0.6071\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6569 - acc: 0.6071\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6567 - acc: 0.6078\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6565 - acc: 0.6080\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6563 - acc: 0.6074\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6561 - acc: 0.6085\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6560 - acc: 0.6075\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6558 - acc: 0.6092\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6556 - acc: 0.6090\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6555 - acc: 0.6092\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6554 - acc: 0.6084\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6103\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6096\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6099\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6100\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6107\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6105\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6111\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6120\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6118\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6051\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6587 - acc: 0.6043\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6056\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6055\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6055\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6057\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6057\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6062\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6065\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6073\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6066\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6072\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6067\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6071\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6077\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6078\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6079\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6077\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6074\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6077\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6077\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6076\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6078\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6075\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6076\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6075\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6080\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6081\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6084\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6087\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6571 - acc: 0.6078\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6571 - acc: 0.6078\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6570 - acc: 0.6089\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6568 - acc: 0.6090\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6567 - acc: 0.6094\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6565 - acc: 0.6085\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6564 - acc: 0.6099\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6562 - acc: 0.6106\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6561 - acc: 0.6104\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6560 - acc: 0.6099\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6558 - acc: 0.6105\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6557 - acc: 0.6107\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6555 - acc: 0.6108\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6554 - acc: 0.6091\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6098\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6087\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6089\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6101\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6093\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6104\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6108\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6110\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6110\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6107\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6104\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6102\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6109\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6110\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6111\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6049\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6041\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6063\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6048\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6065\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6064\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6049\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6065\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6067\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6066\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6072\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6066\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6070\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6073\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6075\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6072\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6070\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6067\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6070\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6072\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6071\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6071\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6073\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6073\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6072\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6071\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6072\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6068\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6067\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6563 - acc: 0.6094\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6566 - acc: 0.6078\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6564 - acc: 0.6103\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6559 - acc: 0.6082\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6558 - acc: 0.6093\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6559 - acc: 0.6105\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6556 - acc: 0.6089\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6116\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6112\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6088\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6113\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6099\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6104\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6103\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6105\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6112\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6107\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6103\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6107\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6114\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6107\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6113\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6116\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6110\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6113\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6119\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6113\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6119\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6121\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6118\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6052\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6036\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6051\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6053\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6060\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6036\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6065\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6063\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6058\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6063\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6070\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6068\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6062\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6075\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6074\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6058\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6068\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6075\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6076\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6065\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6072\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6073\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6074\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6076\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6072\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6074\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6076\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6076\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6078\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6565 - acc: 0.6074\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6563 - acc: 0.6078\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6562 - acc: 0.6082\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6561 - acc: 0.6091\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6560 - acc: 0.6092\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6558 - acc: 0.6092\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6556 - acc: 0.6089\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6555 - acc: 0.6089\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6554 - acc: 0.6087\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6088\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6089\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6089\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6078\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6078\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6081\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6090\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6083\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6088\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6091\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6090\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6095\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6089\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6089\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6095\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6100\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6099\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6095\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6092\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6098\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6103\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6071\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6068\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6066\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6059\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6065\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6066\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6068\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6068\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6069\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6070\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6073\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6075\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6073\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6076\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6071\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6071\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6069\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6070\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6070\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6071\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6071\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6070\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6071\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6075\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6079\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6078\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6081\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6081\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6082\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6561 - acc: 0.6072\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6559 - acc: 0.6076\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6558 - acc: 0.6072\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6556 - acc: 0.6083\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6555 - acc: 0.6078\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6090\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6088\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6084\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6082\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6084\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6098\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6096\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6099\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6096\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6095\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6096\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6106\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6103\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6109\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6107\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6107\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6107\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6105\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6103\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6106\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6104\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6103\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6103\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6104\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6103\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6039\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6044\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6043\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6044\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6048\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6052\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6055\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6063\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6067\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6064\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6069\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6066\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6070\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6070\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6068\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6069\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6068\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6069\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6071\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6067\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6066\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6072\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6071\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6075\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6077\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6074\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6079\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6073\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6106\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6113\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6111\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6110\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6118\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6126\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6135\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6146\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6141\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6144\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6153\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6137\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6145\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6140\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6142\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6146\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6141\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6141\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6142\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6142\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6142\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6139\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6143\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6146\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6143\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6150\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6154\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6148\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6148\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6055\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6587 - acc: 0.6043\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6053\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6047\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6054\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6056\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6051\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6056\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6052\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6064\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6052\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6053\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6065\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6059\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6058\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6058\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6057\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6064\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6059\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6069\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6066\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6073\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6070\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6070\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6072\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6069\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6069\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6068\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6073\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6554 - acc: 0.6116\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6117\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6125\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6117\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6121\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6122\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6135\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6133\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6138\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6141\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6141\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6147\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6138\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6139\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6136\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6138\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6137\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6136\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6147\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6144\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6143\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6140\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6143\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6140\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6153\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6147\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6148\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6150\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6152\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6154\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6049\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6051\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6057\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6047\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6053\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6056\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6053\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6052\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6051\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6067\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6068\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6059\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6075\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6064\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6073\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6068\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6069\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6074\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6068\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6079\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6077\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6072\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6073\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6070\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6071\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6072\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6076\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6074\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6103\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6112\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6118\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6117\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6118\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6107\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6119\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6122\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6118\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6127\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6117\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6120\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6117\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6122\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6118\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6118\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6115\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6123\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6126\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6120\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6131\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6126\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6133\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6128\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6126\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6126\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6126\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6133\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6133\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6133\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6593 - acc: 0.6039\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6590 - acc: 0.6036\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6043\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6043\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6587 - acc: 0.6034\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6046\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6038\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6046\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6053\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6054\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6063\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6058\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6063\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6066\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6066\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6065\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6070\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6066\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6068\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6076\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6078\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6080\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6076\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6079\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6077\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6072\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6071\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6076\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6078\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6090\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6082\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6084\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6090\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6089\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6104\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6104\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6116\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6093\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6099\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6090\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6099\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6097\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6081\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6106\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6080\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6106\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6084\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6100\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6096\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6085\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6095\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6093\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6105\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6090\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6109\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6101\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6114\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6112\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6110\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6050\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6042\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6052\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6036\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6047\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6039\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6050\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6043\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6045\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6052\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6051\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6058\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6059\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6063\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6070\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6063\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6071\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6064\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6069\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6069\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6071\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6070\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6069\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6071\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6069\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6075\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6074\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6072\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6566 - acc: 0.6060\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6566 - acc: 0.6064\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6563 - acc: 0.6071\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6560 - acc: 0.6065\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6557 - acc: 0.6064\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6556 - acc: 0.6067\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6555 - acc: 0.6075\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6554 - acc: 0.6089\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6089\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6091\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6104\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6094\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6090\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6088\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6092\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6093\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6094\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6109\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6098\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6101\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6097\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6110\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6112\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6122\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6115\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6115\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6128\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6130\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6133\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6597 - acc: 0.6046\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6598 - acc: 0.6033\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6597 - acc: 0.6042\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6593 - acc: 0.6032\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6590 - acc: 0.6040\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6032\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6037\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6038\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6041\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6038\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6045\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6053\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6055\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6050\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6051\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6056\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6055\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6066\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6057\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6055\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6065\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6060\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6065\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6069\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6060\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6067\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6061\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 2s 3us/sample - loss: 0.6569 - acc: 0.6055\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6064\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6063\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6085\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6105\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6102\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6098\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6101\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6104\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6110\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6123\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6117\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6122\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6125\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6108\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6106\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6107\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6097\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6102\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6096\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 3us/sample - loss: 0.6519 - acc: 0.6097\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 3us/sample - loss: 0.6519 - acc: 0.6106\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6115\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6118\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6109\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6113\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6118\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6117\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6120\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6121\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6124\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6114\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6120\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6046\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6045\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6046\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6047\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6055\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6044\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6047\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6054\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6054\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6063\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6066\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6061\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6058\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6059\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6062\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6058\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6061\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6063\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6062\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6062\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6063\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6062\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6061\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6065\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6064\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6062\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6062\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6056\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6059\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6092\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6112\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6107\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6125\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6123\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6125\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6126\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6129\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6144\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6136\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6138\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6132\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6139\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6133\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6132\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6140\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6138\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6141\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6149\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6145\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6143\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6151\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6151\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6159\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6156\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6154\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6148\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6157\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6150\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6153\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6051\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6587 - acc: 0.6051\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6052\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6054\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6059\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6061\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6059\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6059\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6061\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6068\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6067\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6071\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6067\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6069\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6064\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6070\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6068\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6073\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6076\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6077\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6079\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6075\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6078\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6078\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6080\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6081\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6087\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6084\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6087\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6068\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6077\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6549 - acc: 0.6085\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6078\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6078\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6072\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6080\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6087\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6085\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6089\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6095\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6095\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6095\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6092\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6097\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6094\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6093\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6092\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6090\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6089\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6099\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6103\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6101\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6091\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6101\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6109\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6110\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6109\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6113\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6115\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6050\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6050\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6054\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6048\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6058\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6055\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6060\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6053\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6058\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6058\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6059\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6060\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6064\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6066\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6067\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6074\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6071\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6073\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6074\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6077\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6080\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6079\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6074\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6075\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6074\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6077\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6075\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6077\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6076\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6081\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6132\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6141\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6145\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6142\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6151\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6152\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6152\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6143\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6149\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6149\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6150\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6150\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6510 - acc: 0.6148\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6139\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6508 - acc: 0.6156\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6146\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6147\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6144\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6149\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6508 - acc: 0.6141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6159\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6136\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6153\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6124\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6164\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6506 - acc: 0.6137\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6499 - acc: 0.6168\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6503 - acc: 0.6167\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6140\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6510 - acc: 0.6163\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6591 - acc: 0.6042\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6054\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6051\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6050\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6047\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6052\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6044\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6057\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6058\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6058\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6056\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6052\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6058\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6056\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6059\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6063\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6060\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6065\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6059\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6067\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6067\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6065\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6062\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6071\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6073\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6070\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6068\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6067\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6069\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6065\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6100\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6105\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6118\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6124\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6123\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6127\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6119\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6126\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6128\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6128\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6130\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6130\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6136\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6137\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6145\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6143\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6146\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6150\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6155\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6510 - acc: 0.6151\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6153\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6508 - acc: 0.6157\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6154\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6506 - acc: 0.6162\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6506 - acc: 0.6157\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6505 - acc: 0.6157\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6504 - acc: 0.6164\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6503 - acc: 0.6166\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6503 - acc: 0.6163\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6502 - acc: 0.6162\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6593 - acc: 0.6038\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6591 - acc: 0.6042\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6590 - acc: 0.6040\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6039\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6587 - acc: 0.6041\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6038\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6042\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6033\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6039\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6048\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6049\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6047\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6050\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6053\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6052\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6057\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6058\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6058\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6065\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6064\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6073\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6066\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6070\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6067\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6065\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6066\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6065\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6065\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6063\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6071\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6551 - acc: 0.6069\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6074\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6078\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6081\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6546 - acc: 0.6087\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6087\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6089\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6543 - acc: 0.6092\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6094\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6095\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6097\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6092\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6096\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6090\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6090\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6095\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6106\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6104\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6103\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6106\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6111\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6104\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6117\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 3us/sample - loss: 0.6529 - acc: 0.6104\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6111\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6116\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6109\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 3us/sample - loss: 0.6527 - acc: 0.6111\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 3us/sample - loss: 0.6527 - acc: 0.6108\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6066\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6058\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6066\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6053\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6065\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6064\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6060\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6067\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6066\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6065\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6068\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6068\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6066\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6070\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6070\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6064\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6070\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6059\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6060\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6066\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6069\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6065\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6063\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6063\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6066\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6063\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6062\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6062\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6063\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6096\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6096\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6099\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6099\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6114\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6125\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6114\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6115\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6108\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6108\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6126\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6530 - acc: 0.6108\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6122\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6124\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6115\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6128\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6525 - acc: 0.6128\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6128\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6122\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6123\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6120\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6122\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6119\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6117\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6117\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6120\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6122\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6127\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6131\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6133\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6592 - acc: 0.6038\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6590 - acc: 0.6036\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6589 - acc: 0.6044\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6033\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6586 - acc: 0.6043\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6041\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6042\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6039\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6054\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6045\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6058\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6055\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6058\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6062\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6059\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6059\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6059\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6062\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6065\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6061\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6059\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6064\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6063\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6062\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6062\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6055\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6058\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6056\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6056\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6058\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6103\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6539 - acc: 0.6110\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6118\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6120\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6128\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6117\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6129\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6134\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6129\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6126\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6130\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6130\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6522 - acc: 0.6148\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6133\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6140\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6130\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6517 - acc: 0.6131\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6136\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6143\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6147\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6513 - acc: 0.6147\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6150\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6145\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6155\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6510 - acc: 0.6145\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6152\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6147\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6150\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6146\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6063\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6595 - acc: 0.6031\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6601 - acc: 0.6027\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6600 - acc: 0.6023\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6046\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6052\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6050\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6588 - acc: 0.6056\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6042\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6071\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6071\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6047\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6075\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6060\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6067\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6081\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6062\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6073\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6073\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6064\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6076\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6076\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6072\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6075\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6075\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6074\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6074\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6072\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6075\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6078\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6557 - acc: 0.6074\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6557 - acc: 0.6064\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6079\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6552 - acc: 0.6084\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6553 - acc: 0.6082\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6550 - acc: 0.6085\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6089\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6548 - acc: 0.6092\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6547 - acc: 0.6084\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6545 - acc: 0.6102\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6105\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6544 - acc: 0.6091\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6542 - acc: 0.6111\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6109\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6541 - acc: 0.6102\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6540 - acc: 0.6116\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6107\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6538 - acc: 0.6107\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6537 - acc: 0.6107\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6536 - acc: 0.6112\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6124\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6535 - acc: 0.6114\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6117\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6534 - acc: 0.6114\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6121\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6533 - acc: 0.6125\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6115\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6116\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6114\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6117\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6062\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6583 - acc: 0.6047\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6581 - acc: 0.6063\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6051\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6049\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6060\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6057\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6060\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6062\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6574 - acc: 0.6059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6072\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6070\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6066\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6073\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6073\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6070\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6075\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6076\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6080\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6077\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6077\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6074\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6075\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6078\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6078\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6072\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6079\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6078\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6076\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6074\n",
      "Epoch 1/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6532 - acc: 0.6105\n",
      "Epoch 2/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6531 - acc: 0.6114\n",
      "Epoch 3/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6529 - acc: 0.6119\n",
      "Epoch 4/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6528 - acc: 0.6131\n",
      "Epoch 5/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6527 - acc: 0.6135\n",
      "Epoch 6/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6526 - acc: 0.6123\n",
      "Epoch 7/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6524 - acc: 0.6132\n",
      "Epoch 8/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6523 - acc: 0.6132\n",
      "Epoch 9/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6521 - acc: 0.6137\n",
      "Epoch 10/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6520 - acc: 0.6133\n",
      "Epoch 11/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6519 - acc: 0.6140\n",
      "Epoch 12/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6518 - acc: 0.6140\n",
      "Epoch 13/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6516 - acc: 0.6145\n",
      "Epoch 14/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6515 - acc: 0.6139\n",
      "Epoch 15/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6142\n",
      "Epoch 16/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6514 - acc: 0.6136\n",
      "Epoch 17/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6512 - acc: 0.6142\n",
      "Epoch 18/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6139\n",
      "Epoch 19/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6511 - acc: 0.6136\n",
      "Epoch 20/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6510 - acc: 0.6140\n",
      "Epoch 21/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6141\n",
      "Epoch 22/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6509 - acc: 0.6140\n",
      "Epoch 23/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6508 - acc: 0.6139\n",
      "Epoch 24/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6507 - acc: 0.6135\n",
      "Epoch 25/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6506 - acc: 0.6135\n",
      "Epoch 26/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6506 - acc: 0.6139\n",
      "Epoch 27/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6505 - acc: 0.6142\n",
      "Epoch 28/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6505 - acc: 0.6139\n",
      "Epoch 29/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6504 - acc: 0.6139\n",
      "Epoch 30/30\n",
      "22779/22779 [==============================] - 0s 2us/sample - loss: 0.6504 - acc: 0.6132\n",
      "Epoch 1/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6585 - acc: 0.6053\n",
      "Epoch 2/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6584 - acc: 0.6049\n",
      "Epoch 3/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6582 - acc: 0.6055\n",
      "Epoch 4/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6580 - acc: 0.6058\n",
      "Epoch 5/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6579 - acc: 0.6060\n",
      "Epoch 6/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6578 - acc: 0.6060\n",
      "Epoch 7/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6577 - acc: 0.6058\n",
      "Epoch 8/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6576 - acc: 0.6061\n",
      "Epoch 9/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6575 - acc: 0.6061\n",
      "Epoch 10/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6573 - acc: 0.6065\n",
      "Epoch 11/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6572 - acc: 0.6060\n",
      "Epoch 12/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6571 - acc: 0.6062\n",
      "Epoch 13/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6570 - acc: 0.6067\n",
      "Epoch 14/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6070\n",
      "Epoch 15/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6569 - acc: 0.6074\n",
      "Epoch 16/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6568 - acc: 0.6074\n",
      "Epoch 17/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6567 - acc: 0.6071\n",
      "Epoch 18/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6073\n",
      "Epoch 19/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6076\n",
      "Epoch 20/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6566 - acc: 0.6081\n",
      "Epoch 21/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6083\n",
      "Epoch 22/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6565 - acc: 0.6083\n",
      "Epoch 23/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6082\n",
      "Epoch 24/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6076\n",
      "Epoch 25/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6564 - acc: 0.6079\n",
      "Epoch 26/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6078\n",
      "Epoch 27/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6087\n",
      "Epoch 28/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6563 - acc: 0.6087\n",
      "Epoch 29/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6088\n",
      "Epoch 30/30\n",
      "602194/602194 [==============================] - 1s 2us/sample - loss: 0.6562 - acc: 0.6087\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    X_ros, y_ros = ros.fit_resample(X_fit, data_Y.values)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_ros2, y_ros2, test_size = 0.3, shuffle = True)\n",
    "    model.fit(x_train, y_train, epochs=30, batch_size=22779)\n",
    "    X_ros, y_ros = ros.fit_resample(X_fit, data_Y.values)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_ros, y_ros, test_size = 0.3, shuffle = True)\n",
    "    model.fit(x_train, y_train, epochs=30, batch_size=602194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_orig, x_val_orig, y_train_orig, y_val_orig = train_test_split(data_X, data_Y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9763/9763 [==============================] - 1s 107us/sample - loss: 0.6721 - acc: 0.5838\n",
      "Loss =  0.672072074403043\n",
      "Accuracy =  0.5838369\n"
     ]
    }
   ],
   "source": [
    "# Test, Loss and accuracy\n",
    "loss_and_metrics = model.evaluate(x_val, y_val)\n",
    "print('Loss = ',loss_and_metrics[0])\n",
    "print('Accuracy = ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6077289242084742"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = model.predict_classes(X_pos).flatten()\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = model.predict_classes(X_neg).flatten()\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42662790971725084"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pos, y_pos = extrac_one_label(x_val_orig, y_val_orig, 1)\n",
    "y_pospred = model.predict_classes(X_pos).flatten()\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = model.predict_classes(X_neg).flatten()\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4310929127892009"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_t1 = imputer.transform(x_val_orig)\n",
    "x_val_t2 = scaler.transform(x_val_t1)\n",
    "X_pos, y_pos = extrac_one_label(x_val_t2, y_val_orig, 1)\n",
    "y_pospred = model.predict_classes(X_pos).flatten()\n",
    "X_neg, y_neg = extrac_one_label(x_val_t2, y_val_orig, 0)\n",
    "y_negpred = model.predict_classes(X_neg).flatten()\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_fit=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(data_X, data_Y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tree optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;30;41mDepth: 1\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.490556563616237 0.490556563616237\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.490556563616237 0.490556563616237\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.490556563616237 0.490556563616237\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "0.490556563616237 0.48379255929792364\n",
      "\u001b[0;30;41mbest values are:[51, 8, 10, 12, 0.0, 0.48379255929792364]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 6\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5201748652752868 0.5207965737263389\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "0.5206055343179636 0.5206055343179636\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "0.5206055343179636 0.5214933478294266\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4774913496912164\n",
      "\u001b[0;30;41mbest values are:[151, 6, 29, 14, 0.0, 0.4774913496912164]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 11\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5140027781804024\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.509621035180651\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5126837343372279\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48282172569393045\n",
      "\u001b[0;30;41mbest values are:[97, 14, 14, 22, 0.0, 0.48397215779337005]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 16\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.503181402721037\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48797004061335536\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4946347763896251\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48479899477992616\n",
      "\u001b[0;30;41mbest values are:[75, 9, 12, 31, 0.0, 0.48551537717762605]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 21\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4963283243487035\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4863105806547814\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48152934597000624\n",
      "max_depth\n",
      "0.5214933478294266 0.47445946862247323\n",
      "\u001b[0;30;41mbest values are:[101, 6, 10, 4, 0.0, 0.47445946862247323]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 26\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.49946446683647683\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47617266783748985\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.483931414765805\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "0.5214933478294266 0.4844027046100996\n",
      "\u001b[0;30;41mbest values are:[144, 8, 14, 43, 0.0, 0.4844027046100996]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 31\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5047084396281678\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4836459722371068\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47334810073953487\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48032540753214964\n",
      "\u001b[0;30;41mbest values are:[148, 8, 10, 2, 0.0, 0.4746874778462874]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 36\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5033517447226706\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.479749389044249\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "0.5214933478294266 0.48645487133136067\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48537078285833685\n",
      "\u001b[0;30;41mbest values are:[105, 8, 10, 26, 0.0, 0.48790218673173846]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 41\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5025015276533995\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4828242814727996\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "0.5214933478294266 0.4883914236773668\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4900796664811391\n",
      "\u001b[0;30;41mbest values are:[66, 8, 10, 46, 0.0, 0.4901214209234651]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 46\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.49982662712163517\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48185121158362815\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47421709756835884\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48477554952060925\n",
      "\u001b[0;30;41mbest values are:[88, 7, 10, 1, 0.0, 0.48817960414313843]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 51\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5041830714745115\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48084786189409845\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47208313772439453\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4688152718730242\n",
      "\u001b[0;30;41mbest values are:[49, 8, 11, 3, 0.0, 0.47227013726723394]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 56\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5025739302700877\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4821158829167262\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4910584312479865\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "0.5214933478294266 0.49144311875271207\n",
      "\u001b[0;30;41mbest values are:[239, 8, 8, 50, 0.0, 0.49144311875271207]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 61\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.500619492518914\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48300412729007786\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4861749616947258\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4877203392546982\n",
      "\u001b[0;30;41mbest values are:[100, 9, 10, 32, 0.0, 0.4877203392546982]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 66\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5034789486053471\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47929267925166813\n",
      "max-features\n",
      "Reducing step size to:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.483229409697649\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "0.5214933478294266 0.4841911546082424\n",
      "\u001b[0;30;41mbest values are:[76, 8, 11, 19, 0.0, 0.48421451606335386]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 71\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5009527476964724\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48016108657552575\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48887319728642215\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48824453973445864\n",
      "\u001b[0;30;41mbest values are:[19, 11, 10, 49, 0.0, 0.4884041233768567]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 76\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.504687253599766\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48230921974796404\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "0.5214933478294266 0.48910606752501445\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "0.5214933478294266 0.48579209409487195\n",
      "\u001b[0;30;41mbest values are:[21, 8, 10, 33, 0.0, 0.48579209409487195]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 81\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5037391406533235\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4800300778608629\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.48451234926431014\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "0.5214933478294266 0.4862810319805674\n",
      "\u001b[0;30;41mbest values are:[76, 8, 10, 30, 0.0, 0.4862810319805674]\u001b[0m\n",
      "done\n",
      "\u001b[0;30;41mDepth: 86\u001b[0m\n",
      "min_samples\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.5032356585475317\n",
      "min_samples_split\n",
      "Reducing step size to:  4\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4797238159194538\n",
      "max-features\n",
      "Reducing step size to:  5\n",
      "Reducing step size to:  2\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.4733845071654019\n",
      "max_depth\n",
      "Reducing step size to:  25\n",
      "Reducing step size to:  12\n",
      "Reducing step size to:  6\n",
      "Reducing step size to:  3\n",
      "Reducing step size to:  1\n",
      "0.5214933478294266 0.47768926640081966\n",
      "\u001b[0;30;41mbest values are:[58, 8, 10, 2, 0.0, 0.47490294707239056]\u001b[0m\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "crit_list =[]\n",
    "parameters = []\n",
    "crit = 0.4\n",
    "top_crit = 0.4\n",
    "top_list = []\n",
    "tops = []\n",
    "for i in range(1, 90,5):\n",
    "    \n",
    "    print('\\x1b[0;30;41m' + 'Depth: ' + str(i) + '\\x1b[0m')\n",
    "\n",
    "    print('min_samples')\n",
    "    params_s, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,2,\n",
    "                   1,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 6,option = 'min_samples_split')\n",
    "    crit_list.append(crit)\n",
    "    tops.append(top)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    print('min_samples_split')\n",
    "    params_l, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,params_s,\n",
    "                   1,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 8,option = 'min_samples_leaf')\n",
    "    crit_list.append(crit)\n",
    "    tops.append(top)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    print('max-features')\n",
    "    params_f, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,params_s,\n",
    "                   params_l,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 10,option = 'max_features')\n",
    "    crit_list.append(crit)\n",
    "    tops.append(top)\n",
    "    print(top_crit,crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print('max_depth')\n",
    "    params_d, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "               i,params_s,\n",
    "               params_l,params_f,\n",
    "               0.000, threshold = 0.0001, steps = 100, stepmax = 50,option = 'max_depth')\n",
    "    crit_list.append(crit)\n",
    "    tops.append(top)\n",
    "#     print(crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    \n",
    "    print('\\x1b[0;30;41m' + 'best values are:'  + str(top) + '\\x1b[0m')\n",
    "    top_list.append(top_all)\n",
    "    print('done')\n",
    "    results = [params_d,params_s,params_l,params_f,0.001,crit]\n",
    "    parameters.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_list =[]\n",
    "parameters = []\n",
    "crit = 0.4\n",
    "top_crit = 0.4\n",
    "top_list = []\n",
    "for i in range(1, 100,10):\n",
    "    \n",
    "    print('\\x1b[0;30;41m' + 'Depth: ' + str(i) + '\\x1b[0m')\n",
    "    \n",
    "    print('max_depth')\n",
    "    params_d, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "               i,params_s,\n",
    "               params_l,params_f,\n",
    "               0.000, threshold = 0.0001, steps = 100, stepmax = 50,option = 'max_depth')\n",
    "    crit_list.append(crit)\n",
    "    \n",
    "    print('min_samples')\n",
    "    params_s, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,2,\n",
    "                   1,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 6,option = 'min_samples_split')\n",
    "    crit_list.append(crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    print('min_samples_split')\n",
    "    params_l, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,params_s,\n",
    "                   1,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 8,option = 'min_samples_leaf')\n",
    "    crit_list.append(crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    print('max-features')\n",
    "    params_f, crit, top = tree_optimizer(x_train, y_train, x_val, y_val,\n",
    "                   i,params_s,\n",
    "                   params_l,8,\n",
    "                   0.000, threshold = 0.0001, steps = 100, stepmax = 10,option = 'max_features')\n",
    "    crit_list.append(crit)\n",
    "    print(top_crit,crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "\n",
    "#     print(crit)\n",
    "    if top[-1] > top_crit:\n",
    "        top_all = top\n",
    "        top_crit = top[-1]\n",
    "    print(top_crit,crit)\n",
    "    \n",
    "    print('\\x1b[0;30;41m' + 'best values are:'  + str(top) + '\\x1b[0m')\n",
    "    top_list.append(top_all)\n",
    "    print('done')\n",
    "    results = [params_d,params_s,params_l,params_f,0.000,crit]\n",
    "    parameters.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run forest optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop no:  0  crit is:  0.45  est is:  1\n",
      "loop no:  1  crit is:  0.5272380867183059  est is:  6\n",
      "loop no:  2  crit is:  0.5293774125266112  est is:  11\n",
      "loop no:  3  crit is:  0.5275261362216169  est is:  16\n",
      "Reducing step size to:  2\n",
      "loop no:  4  crit is:  0.5293774125266112  est is:  11\n",
      "loop no:  5  crit is:  0.5295038105347251  est is:  13\n",
      "loop no:  6  crit is:  0.5284166842853144  est is:  15\n",
      "Reducing step size to:  1\n",
      "loop no:  7  crit is:  0.5295038105347251  est is:  13\n",
      "loop no:  8  crit is:  0.5273525254253094  est is:  14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converger(x_train, y_train, x_val, y_val, threshold = 0.0001, steps = 100, stepmax = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test forest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5846288219586302"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 76,\n",
    "                             criterion = \"entropy\",\n",
    "                             max_depth=97,\n",
    "                             min_samples_split = 5,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 8,\n",
    "                             random_state=0,\n",
    "                             class_weight = 'balanced',\n",
    "                             min_impurity_decrease = 0.001)\n",
    "clf.fit(x_train, y_train)\n",
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = clf.predict(X_pos)\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = clf.predict(X_neg)\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test forest 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524888977951852"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 76,\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 3,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 31,\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 11.55,0:0.85752},\n",
    "                             min_impurity_decrease = 0.0)\n",
    "clf.fit(x_train, y_train)\n",
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = clf.predict(X_pos)\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = clf.predict(X_neg)\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190957696049663"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 106,\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 6,\n",
    "                             min_samples_leaf = 29,\n",
    "                             max_features = 16,\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 11.55,0:0.85752},\n",
    "                             min_impurity_decrease = 0.0)\n",
    "clf.fit(x_train, y_train)\n",
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = clf.predict(X_pos)\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = clf.predict(X_neg)\n",
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try selecting k best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = RandomForestClassifier(n_estimators = 76,\n",
    "                             criterion = \"entropy\",\n",
    "                             max_depth=97,\n",
    "                             min_samples_split = 5,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 'sqrt',\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 11.55,0:0.85752},\n",
    "                             min_impurity_decrease = 0.001)\n",
    "    return kbest,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = RandomForestClassifier(n_estimators = 76,\n",
    "                             criterion = \"entropy\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 3,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 31,\n",
    "                             random_state=0,\n",
    "                             class_weight = 'balanced',\n",
    "                             min_impurity_decrease = 0.00)\n",
    "    return kbest,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Best forest\n",
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = RandomForestClassifier(n_estimators = 13,\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 6,\n",
    "                             min_samples_leaf = 29,\n",
    "                             max_features = 16,\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 24.9,0:1.71},\n",
    "                             min_impurity_decrease = 0.0000)\n",
    "    return kbest,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = DecisionTreeClassifier(\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 3,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 31,\n",
    "                             class_weight = {1: 11.55,0:0.85752},\n",
    "                             min_impurity_decrease = 0.00)\n",
    "    return kbest,clf \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Best tree\n",
    "\n",
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = DecisionTreeClassifier(\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 6,\n",
    "                             min_samples_leaf = 29,\n",
    "                             max_features = 16,\n",
    "                             class_weight = {1: 24.9,0:1.71},\n",
    "                             min_impurity_decrease = 0.0001)\n",
    "    return kbest,clf \n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different amount of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_k = []\n",
    "for i in range(0,1):\n",
    "    kbest, clf = k_test(i)\n",
    "    clf = make_pipeline(kbest, clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # y_pred = clf.predict(x_val)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    sumpos = sum(y_pospred==y_pos)/len(y_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    sumneg = sum(y_negpred==y_neg)/len(y_neg)\n",
    "    score = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "    results_k.append([score,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_k[np.argmax(np.array(results_k)[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5296278613907957, 16],\n",
       " [0.5282420547409288, 20],\n",
       " [0.527172425380073, 24],\n",
       " [0.5275672117315945, 28],\n",
       " [0.5244521949392277, 32],\n",
       " [0.5213323892558439, 36],\n",
       " [0.523457258607678, 40],\n",
       " [0.522228047088581, 44],\n",
       " [0.5193287518587004, 48],\n",
       " [0.5177676900119991, 52]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5293348860264712, 20]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_k2 = []\n",
    "for i in range(16,23):\n",
    "    kbest, clf = k_test(i)\n",
    "    clf = make_pipeline(kbest, clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # y_pred = clf.predict(x_val)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    sumpos = sum(y_pospred==y_pos)/len(y_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    sumneg = sum(y_negpred==y_neg)/len(y_neg)\n",
    "    score = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "    results_k2.append([score,i])\n",
    "results_k2[np.argmax(np.array(results_k2)[:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5267035809688665, 25],\n",
       " [0.526365418209532, 26],\n",
       " [0.5275939015546748, 27],\n",
       " [0.5270423659327679, 28],\n",
       " [0.528142831106037, 29]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = 0\n",
    "for i in range(0,5):\n",
    "    kbest, clf = k_test(20)\n",
    "    clf = make_pipeline(kbest, clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # y_pred = clf.predict(x_val)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    sumpos = sum(y_pospred==y_pos)/len(y_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    sumneg = sum(y_negpred==y_neg)/len(y_neg)\n",
    "    score = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "    if score_max < score:\n",
    "        clf_save = clf\n",
    "        score_max = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5293348860264712"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.531466626142353"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf_save\n",
    "X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "y_pospred = clf.predict(X_pos)\n",
    "sumpos = sum(y_pospred==y_pos)/len(y_pos)\n",
    "X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "y_negpred = clf.predict(X_neg)\n",
    "sumneg = sum(y_negpred==y_neg)/len(y_neg)\n",
    "score = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2480\n",
      "2485\n",
      "2490\n",
      "2495\n",
      "2500\n",
      "2505\n"
     ]
    }
   ],
   "source": [
    "scores2 = []\n",
    "for i in range(2480,2510,5):\n",
    "    print(i)\n",
    "    for j in range(1700,1730,5):\n",
    "        weights = {1:(i/100),0:(j/1000)}\n",
    "#         print(weights)\n",
    "        clf = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                     max_depth=6,\n",
    "                                     min_samples_split = 6,\n",
    "                                     min_samples_leaf = 29,\n",
    "                                     max_features = 16,\n",
    "                                     class_weight = weights,\n",
    "                                     min_impurity_decrease = 0.00)\n",
    "        clf.fit(x_train, y_train)\n",
    "        X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "        y_pospred = clf.predict(X_pos)\n",
    "        X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "        y_negpred = clf.predict(X_neg)\n",
    "#         print((sum(y_negpred==y_neg)/len(y_neg) + sum(y_pospred==y_pos)/len(y_pos)))\n",
    "        if (sum(y_negpred==y_neg)/len(y_neg) + sum(y_pospred==y_pos)/len(y_pos)) > 1:\n",
    "            scores2.append((i/100,j/100,f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 25.05, 0: 1.725}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5259602694499625, 24.95, 17.15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_data = np.array(scores2)\n",
    "x = arr_data[:,0]\n",
    "y = arr_data[:,1]\n",
    "z = arr_data[:,2]\n",
    "np.max(z), x[np.argmax(z)],y[np.argmax(z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gaussian_filter(z, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17d0c79b5c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(np.array([x,y,z]).T)\n",
    "df.columns = ['X_value','Y_value','Z_value']\n",
    "df['Z_value'] = pd.to_numeric(df['Z_value'])\n",
    "pivotted= df.pivot('Y_value','X_value','Z_value')\n",
    "sns.heatmap(pivotted,cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final choice of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 11.55, 0: 0.85752}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {1: 11.51,0:0.86}\n",
    "weights = {1: 11.55,0:0.85752}\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5293348860264712"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = imputer.transform(data_test_X)\n",
    "test_X_fit=scaler.transform(test_X)\n",
    "y_target = clf_save.predict(test_X_fit)\n",
    "sum(y_target==0),sum(y_target==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "Please only submit the csv files with predicted outcome with its id and target [here](https://www.kaggle.com/t/b3dc81e90d32436d93d2b509c98d0d71). Your column should only contain `0` and `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results was obtained with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\train_set.csv\"\n",
    "data_train = pd.read_csv(filename)\n",
    "filename = r\"C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\test_set.csv\"\n",
    "data_test = pd.read_csv(filename)\n",
    "fea_col = data_train.columns[2:]\n",
    "\n",
    "data_Y = data_train['target']\n",
    "data_X = data_train[fea_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_one_label(x_val, y_val, label):\n",
    "    X_pos = x_val[y_val == label]\n",
    "    y_pos = y_val[y_val == label]\n",
    "    return X_pos, y_pos\n",
    "def k_test(i):\n",
    "    kbest = SelectKBest(f_classif, k=i)\n",
    "    clf = RandomForestClassifier(n_estimators = 13,\n",
    "                             criterion = \"gini\",\n",
    "                             max_depth=6,\n",
    "                             min_samples_split = 6,\n",
    "                             min_samples_leaf = 29,\n",
    "                             max_features = 16,\n",
    "                             random_state=0,\n",
    "                             class_weight = {1: 24.9,0:1.71},\n",
    "                             min_impurity_decrease = 0.0000)\n",
    "    return kbest,clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "imputer.fit(data_X)\n",
    "X = imputer.transform(data_X)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_fit=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_fit, data_Y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = 0\n",
    "for i in range(0,5):\n",
    "    kbest, clf = k_test(20)\n",
    "    clf = make_pipeline(kbest, clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # y_pred = clf.predict(x_val)\n",
    "    X_pos, y_pos = extrac_one_label(x_val, y_val, 1)\n",
    "    y_pospred = clf.predict(X_pos)\n",
    "    sumpos = sum(y_pospred==y_pos)/len(y_pos)\n",
    "    X_neg, y_neg = extrac_one_label(x_val, y_val, 0)\n",
    "    y_negpred = clf.predict(X_neg)\n",
    "    sumneg = sum(y_negpred==y_neg)/len(y_neg)\n",
    "    score = f1_score(np.hstack((y_pos,y_neg)), np.hstack((y_pospred,y_negpred)), average='macro')\n",
    "    if score_max < score:\n",
    "        clf_save = clf\n",
    "        score_max = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5305274395237191"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115733, 33067)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_X = data_test.drop(columns=['id'])\n",
    "y_target = clf_save.predict(data_test_X)\n",
    "sum(y_target==0), sum(y_target==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = pd.DataFrame(data_test['id'].copy())\n",
    "data_out.insert(1, \"target\", y_target, True) \n",
    "data_out.to_csv(r'C:\\Users\\cerb_\\Documents\\CCB\\Erw_Std_Info\\Kaggle\\submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148795</th>\n",
       "      <td>248795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148796</th>\n",
       "      <td>248796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148797</th>\n",
       "      <td>248797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148798</th>\n",
       "      <td>248798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148799</th>\n",
       "      <td>248799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target\n",
       "0       100000       0\n",
       "1       100001       0\n",
       "2       100002       0\n",
       "3       100003       0\n",
       "4       100004       0\n",
       "...        ...     ...\n",
       "148795  248795       0\n",
       "148796  248796       0\n",
       "148797  248797       0\n",
       "148798  248798       0\n",
       "148799  248799       0\n",
       "\n",
       "[148800 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
